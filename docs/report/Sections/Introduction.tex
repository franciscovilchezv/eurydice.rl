In this project we are trying to solve the automated musical composition problem using Deep Reinforcement Learning. Solving this problem with the usage of Reinforcement Learning becomes an interesting approach since it enables the interaction between the computer and humans for training which compositions sound good and that way improve the computer's compositional skills. This can become a difficult task to automate, since there is no specific way to measure if one composition would be better or worse than another one. Music quality depends on each user's preferences, because of that, a composition that may sound nice for a group of people, may not sounds as nice as a different composition based on a different group of people's opinion. Based on this, we consider that it is important to create a bridge between computational musical composition and human feedback, reason why Reinforcement Learning can give promising results on this area.

In this report, we will present the results that we have obtained by applying \emph{Q-learning} and \emph{Deep Q-learning}. We have been able to teach the computer which notes are the best to be played after other notes according to the user's criteria by asking them for their feedback after a note or sequence of notes have been player. That way, we were able to generate a melody that match our preferences. We will present the information about past works regarding musical encoding for computational composition, and the usage of reinforcement learning in this area. After that, we will provide information about the approach used for solving this problem and explain the results obtained. Finally, we will mention future steps that we could be taken in this project.