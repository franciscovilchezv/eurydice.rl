Our solution will be based in the usage of Reinforcement Learning and Recurrent Neural Networks for solving the automated musical composition problem. The details of each component of the algorithm are defined as follow:

\begin{description}
  \item [States] Each state will be represented by the sequence of notes that have been played so far. Each note is a represented by the note itself, its duration, the chord and the compositions tonality. Since we will be focused on generating melodies, the chord and composition tonality will be defined as an input. The notes may not be represented by its value itself (i.e $ C $, $D$, $E$, etc), instead we may be using a relative representation based on the tonality or current chord (e.g. $ D $ will be a 1 if we are in a $ D $ chord, either major or minor, $ E $ will be a 2, $ F $ will be a 2.5, $ F\sharp $ will be a 3, and so on.)
  \item [End state] Since we don't want our algorithm to generate infinite amount of notes, we will have an \emph{hyperparameter} that will be used to know when it has reached the limit amount of notes required. In other words, it will tell it when it reached the \emph{end state}.
  \item [Actions] We can see that the possible notes that can follow another note is very broad, because of that, the generation of the next actions will probably include some special criteria, for example, a note can only be followed by a note within an octave up and down of it. Additionally, the \emph{hyperparameter} for the end state will be taken into consideration in order to decide the durations for the notes.
  \item [Transition sampling] The reward generated by the transition will be zero by default unless the human decides that the melody (or part of it) deserves a reward higher than zero. Possible automated methods for this can be implemented in the future, however, one of the goals of this project is to allow the human-computer interaction during the learning process.
  \item [Monte Carlo] Since the amount of states that we can explore is too big, we are considering to use Monte Carlo as our algorithm for reaching the goal state and learn from the experience. Since the a melody may only have a value after a set of notes are generated, we believe this method will be the most suitable for the situation.
  \item [RNN] Since the next note that we want to use depends a lot on the previous notes generated, we consider that the usage of a \emph{Recurrent Neural Network} will allow us to get better results than other type of models.
\end{description}

An attempt to apply Deep Reinforcement Learning to the automatic musical composition problem has been tried in different researches. One of them applied Deep Q-Learning, a Long Short-Term Memory (LSTM) network, a dataset of MIDI compositions and Music Theory Rules for the creation of melodies \cite{deeprl2016music}. Our approach will take into consideration the work done on that paper but it will be focused on allowing the human-computer interaction for the creativity process of the computer. The usage of LSTM networks has considered effective for different researches \cite{deeprl2016music} \cite{eck2002blues}, showing even better results than the usage of other neural networks architectures \cite{briot2019survey}. One of them, is even an open source product which is currently available for usage \cite{magenta2018}. However, for our case, the experience learned from the human-computer interaction will have more weight that any possible training performed with datasets in the LSTM, which will mean that the algorithm is learning based on the user's particular musical taste.

